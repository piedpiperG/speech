{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**实验目标：**\n",
    "\n",
    "通过本实验，你将深入了解和实践说话人识别技术，并掌握利用声音特征进行有效说话人识别的基本方法，了解不同特征和模型对识别准确率的影响。\n",
    "\n",
    "实验的核心目标是使用TIMIT数据集来训练一个说话人识别系统，涵盖数据预处理、特征提取、模型训练和评估等关键步骤。\n",
    "\n",
    "\n",
    "**实验方法：**\n",
    "\n",
    "**1. 数据预处理和划分(可选)：**\n",
    "  - 为了方便大家，我们提供了划分好的TIMIT数据集结构，当然你也可以根据训练结果自行划分该原数据集。\n",
    "  - 原数据集下载地址：https://drive.google.com/file/d/180mSIiXN9RVDV2Xn1xcWNkMRm5J5MjN4/view?usp=sharing\n",
    "  - 我们排除了SA的两个方言句子，并在剩余的8个句子中选取了SX的5个句子和SI的1个句子作为训练集，SI的另外2个句子作为测试集。\n",
    "  \n",
    "**2. 特征提取：**\n",
    "  - 学习并实现包括但不限于MFCC特征等特征的提取，探索声音信号的频率和时间特性。\n",
    "  - 鼓励尝试和比较其他特征提取方法，例如LPCC或声谱图特征，以理解不同特征对识别性能的影响。\n",
    "  \n",
    "**3. 模型选择和训练：**\n",
    "  - 探索并选择适合的分类器和模型进行说话人识别，如GMM、Softmax分类器或深度学习模型。\n",
    "  - 实现模型训练流程，使用训练集数据训练模型。\n",
    "  \n",
    "**4. 评估和分析：**\n",
    "  - 使用准确率作为主要的评价指标在测试集上评估模型性能。\n",
    "  - 对比不同特征和模型的性能，分析其对说话人识别准确率的影响。\n",
    "  - 可视化不同模型的识别结果和错误率，讨论可能的改进方法。\n",
    "\n",
    "**实验要求：**\n",
    "  - 1.选择并实现至少一种特征的提取，并鼓励尝试其他特征提取方法。\n",
    "  - 2.选择并实现至少一种分类器或模型进行说话人识别，并使用准确率评估指标评估其性能。\n",
    "  - 3.通过实验对比、分析和可视化，撰写详细的实验报告，包括实验目的、实验方法、结果分析和结论。\n",
    "  - 4.实验报告应以清晰、逻辑性强的形式呈现，图表和结果应清楚明了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 实验准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T07:47:19.265347800Z",
     "start_time": "2024-04-16T07:47:19.002202200Z"
    }
   },
   "outputs": [],
   "source": [
    "## 导入必要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 可以根据需要导入其他库，比如librosa用于音频处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据预处理(加载数据集)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T07:48:02.753427Z",
     "start_time": "2024-04-16T07:47:19.267441Z"
    }
   },
   "outputs": [],
   "source": [
    "TrainDir = \"Dataset\\TRAIN\"\n",
    "TestDir = \"Dataset\\TEST\"\n",
    "\n",
    "\n",
    "## 请在这里写代码加载我们划分好的TIMIT训练集和测试集\n",
    "\n",
    "def load_timit_dataset(base_path):\n",
    "    speakers_data = {}\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                speaker_id = root.split(os.sep)[-1]\n",
    "                file_path = os.path.join(root, file)\n",
    "                data, samplerate = sf.read(file_path)\n",
    "                if speaker_id not in speakers_data:\n",
    "                    speakers_data[speaker_id] = []\n",
    "                speakers_data[speaker_id].append((data, samplerate))\n",
    "    return speakers_data\n",
    "\n",
    "\n",
    "train_data = load_timit_dataset(TrainDir)\n",
    "test_data = load_timit_dataset(TestDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T07:51:28.595844500Z",
     "start_time": "2024-04-16T07:50:56.342080600Z"
    }
   },
   "outputs": [],
   "source": [
    "## 请编写或使用库函数提取MFCC等音频特征\n",
    "def extract_features(audio_data, samplerate):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=samplerate, n_mfcc=13)\n",
    "    return mfccs\n",
    "\n",
    "\n",
    "def prepare_dataset(speakers_data):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for speaker_id, audios in speakers_data.items():\n",
    "        for audio, rate in audios:\n",
    "            mfcc = extract_features(audio, rate)\n",
    "            features.append(mfcc)\n",
    "            labels.append(speaker_id)\n",
    "    return features, np.array(labels)  # 这里将 labels 转换为 numpy 数组\n",
    "\n",
    "\n",
    "train_data_features, train_data_labels = prepare_dataset(train_data)\n",
    "test_data_features, test_data_labels = prepare_dataset(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型选择和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T07:51:38.816569300Z",
     "start_time": "2024-04-16T07:51:38.038798500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Edgar\\AppData\\Local\\Temp\\ipykernel_13916\\3954231456.py\", line 25, in <module>\n",
      "    gmm.fit(X_train)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py\", line 181, in fit\n",
      "    self.fit_predict(X, y)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py\", line 235, in fit_predict\n",
      "    self._initialize_parameters(X, random_state)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py\", line 115, in _initialize_parameters\n",
      "    cluster.KMeans(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\", line 1526, in fit\n",
      "    labels, inertia, centers, n_iter_ = kmeans_single(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\", line 688, in _kmeans_single_lloyd\n",
      "    with threadpool_limits(limits=1, user_api=\"blas\"):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 72, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 171, in __init__\n",
      "    getattr(self.dynlib, \"openblas_get_num_threads64_\", lambda: None),\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    \"\"\"Return the threading layer of BLIS\"\"\"\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 340, in __init__\n",
      "    class OpenMPController(LibController):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 373, in _load_modules\n",
      "    _ALL_OPENMP_LIBRARIES = OpenMPController.filename_prefixes\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 485, in _find_modules_with_enum_process_module_ex\n",
      "    num_threads[user_api] = limit\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 606, in __init__\n",
      "    This effect is global and impacts the whole Python process. There is no thread level\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 646, in get_version\n",
      "    return super().wrap(ThreadpoolController(), limits=limits, user_api=user_api)\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "## 在这部分，你可以选择不同的分类器和模型如GMM模型来进行实验\n",
    "def flatten_features(features):\n",
    "    # 将特征从三维数组转换为二维数组，以便可以用于GMM\n",
    "    flattened_features = []\n",
    "    for feature in features:\n",
    "        # 使用均值跨时间序列来简化数据，可以尝试其他方法如最大值、中位数等\n",
    "        flattened_features.append(np.mean(feature, axis=1))\n",
    "    return np.vstack(flattened_features)\n",
    "\n",
    "\n",
    "# 数据扁平化\n",
    "X_train = flatten_features(train_data_features)\n",
    "X_test = flatten_features(test_data_features)\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 确定GMM组件的数量\n",
    "n_components = len(np.unique(train_data_labels))\n",
    "\n",
    "# 训练GMM\n",
    "gmm = GaussianMixture(n_components=n_components, covariance_type='diag', max_iter=200, random_state=0)\n",
    "gmm.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 评价指标(准确率Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T07:48:36.682810800Z"
    }
   },
   "outputs": [],
   "source": [
    "## 请编写代码或使用库函数accuracy_score计算测试集上的准确率Accuracy\n",
    "# 对训练数据进行聚类\n",
    "train_labels_gmm = gmm.predict(X_train)\n",
    "\n",
    "# 创建从GMM组件到实际标签的映射\n",
    "from scipy.stats import mode\n",
    "\n",
    "labels_mapping = {}\n",
    "for i in range(n_components):\n",
    "    mask = (train_labels_gmm == i)\n",
    "    # 为每个组件找出最常见的标签\n",
    "    if np.any(mask):\n",
    "        labels_mapping[i] = mode(train_data_labels[mask])[0][0]\n",
    "\n",
    "# 使用映射进行测试数据的预测\n",
    "test_labels_gmm = gmm.predict(X_test)\n",
    "predicted_labels = [labels_mapping[label] for label in test_labels_gmm]\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(test_data_labels, predicted_labels)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6. 分析和可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T07:48:36.684757100Z"
    }
   },
   "outputs": [],
   "source": [
    "## 请使用matplotlib等可视化库对你的实验结果进行可视化分析。\n",
    "## 包括但不限于准确率的对比、错误分类的分析、特征的影响等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 结果讨论\n",
    "讨论你的模型性能，尝试解释为什么某些模型比其他模型表现好，以及可能的改进方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 保存模型（可选）\n",
    "如果需要，可以在这里添加代码保存你的模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
